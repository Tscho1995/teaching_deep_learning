{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Classes-for-building-up-a-computation-graph\" data-toc-modified-id=\"Classes-for-building-up-a-computation-graph-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Classes for building up a computation graph</a></span></li><li><span><a href=\"#Building-up-a-simple-computation-graph:-a-single-neuron\" data-toc-modified-id=\"Building-up-a-simple-computation-graph:-a-single-neuron-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Building up a simple computation graph: a single neuron</a></span></li><li><span><a href=\"#Implementing-Backpropagation\" data-toc-modified-id=\"Implementing-Backpropagation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Implementing Backpropagation</a></span></li><li><span><a href=\"#Let-us-train-a-single-neuron-to-learn-to-add-the-3-inputs\" data-toc-modified-id=\"Let-us-train-a-single-neuron-to-learn-to-add-the-3-inputs-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Let us train a single neuron to learn to add the 3 inputs</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "MiniFlow is not TensorFlow.\n",
    "\n",
    "It is a very minimalistic framework with the goal to introduce students into the idea of\n",
    "- representing a neural network as a computation graph\n",
    "- computing the gradient of the error function with respect to the model parameters by using Reverse-mode autodiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classes for building up a computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class node:\n",
    "    \"\"\"\n",
    "    A graph node can just store a value\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.value = 0.0\n",
    "        self._w = 0.0\n",
    "        self.is_input_for = []\n",
    "        \n",
    "    def compute(self):\n",
    "        pass\n",
    "    \n",
    "    def derive(self, w):\n",
    "        pass\n",
    "        \n",
    "\n",
    "\n",
    "class node_op_unary(node):\n",
    "    \"\"\"\n",
    "    Base class for unary operation nodes,\n",
    "    e.g. Relu(x), abs(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name, input1):\n",
    "        node.__init__(self, name)\n",
    "        self.input1 = input1\n",
    "        input1.is_input_for.append( self )\n",
    "\n",
    "        \n",
    "\n",
    "class node_op_binary(node):\n",
    "    \"\"\"\n",
    "    Base class for binary operation nodes,\n",
    "    e.g. x*y, x+y, x-y\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name, input1, input2):\n",
    "        node.__init__(self, name)\n",
    "        self.input1 = input1\n",
    "        self.input2 = input2\n",
    "        input1.is_input_for.append( self )\n",
    "        input2.is_input_for.append( self )\n",
    "\n",
    "\n",
    "        \n",
    "class node_op_mult(node_op_binary):\n",
    "    \"\"\"\n",
    "    x*y\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name, input1, input2):\n",
    "        node_op_binary.__init__(self, name, input1, input2)\n",
    "    \n",
    "    def compute(self):\n",
    "        self.value = self.input1.value * self.input2.value\n",
    "        \n",
    "    def derive(self, w):\n",
    "        \"\"\"\n",
    "        compute the derivative of this node\n",
    "        with respect to node <w>\n",
    "        \"\"\"\n",
    "        if w==self.input1:\n",
    "            return self.input2.value\n",
    "        elif w==self.input2:\n",
    "            return self.input1.value\n",
    "        \n",
    "\n",
    "        \n",
    "class node_op_add(node_op_binary):\n",
    "    \"\"\"\n",
    "    x+y\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name, input1, input2):\n",
    "        node_op_binary.__init__(self, name, input1, input2)\n",
    "    \n",
    "    def compute(self):\n",
    "        self.value = self.input1.value + self.input2.value\n",
    "        \n",
    "    def derive(self, w):\n",
    "        \"\"\"\n",
    "        compute the derivative of this node\n",
    "        with respect to node <w>\n",
    "        \"\"\"\n",
    "        if w == self.input1:\n",
    "            return 1.0\n",
    "        elif w == self.input2:\n",
    "            return +1.0\n",
    "        \n",
    "\n",
    "        \n",
    "class node_op_sub(node_op_binary):\n",
    "    \"\"\"\n",
    "    x-y\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name, input1, input2):\n",
    "        node_op_binary.__init__(self, name, input1, input2)\n",
    "    \n",
    "    def compute(self):\n",
    "        self.value = self.input1.value - self.input2.value  \n",
    "        \n",
    "    def derive(self, w):\n",
    "        \"\"\"\n",
    "        compute the derivative of this node\n",
    "        with respect to node <w>\n",
    "        \"\"\"\n",
    "        if w == self.input1:\n",
    "            return 1.0\n",
    "        elif w == self.input2:\n",
    "            return -1.0\n",
    "        \n",
    "\n",
    "        \n",
    "class node_op_relu(node_op_unary):\n",
    "    \"\"\"\n",
    "    Relu(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name, input1):\n",
    "        node_op_unary.__init__(self, name, input1)\n",
    "        \n",
    "    def compute(self):\n",
    "        \"\"\"\n",
    "        compute output of this node: Relu(input)\n",
    "        \"\"\"\n",
    "        if self.input1.value < 0.0:\n",
    "            self.value = 0.0\n",
    "        else:\n",
    "            self.value = self.input1.value\n",
    "            \n",
    "            \n",
    "    def derive(self, w):\n",
    "        \"\"\"\n",
    "        compute the derivative of this node\n",
    "        with respect to node <w>\n",
    "        \"\"\"\n",
    "        if w.value < 0.0:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return 1.0\n",
    "            \n",
    "\n",
    "            \n",
    "class node_op_abs(node_op_unary):\n",
    "    \"\"\"\n",
    "    abs(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name, input1):\n",
    "        node_op_unary.__init__(self, name, input1)\n",
    "        \n",
    "    def compute(self):\n",
    "        \"\"\"\n",
    "        compute output of this node: abs(input)\n",
    "        \"\"\"\n",
    "        self.value = abs(self.input1.value)\n",
    "        \n",
    "    def derive(self, w):\n",
    "        \"\"\"\n",
    "        compute the derivative of this node\n",
    "        with respect to node <w>\n",
    "        \"\"\"\n",
    "        if w.value > 0.0:\n",
    "            return 1.0\n",
    "        elif w.value < 0:\n",
    "            return -1.0\n",
    "        else:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building up a simple computation graph: a single neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neuron will have 3 inputs and 3 weights will be learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3 input nodes\n",
    "w1 = node(\"w1 (input)\")\n",
    "w2 = node(\"w2 (input)\")\n",
    "w3 = node(\"w3 (input)\")\n",
    "\n",
    "# 3 parameter nodes (weights)\n",
    "w4 = node(\"w4 (weight)\")\n",
    "w5 = node(\"w5 (weight)\")\n",
    "w6 = node(\"w6 (weight)\")\n",
    "\n",
    "# computation of activation\n",
    "w7 = node_op_mult(\"w7=w1*w4\", w1,w4)\n",
    "w8 = node_op_mult(\"w8=w2*w5\", w2,w5)\n",
    "w9 = node_op_mult(\"w9=w3*w6\", w3,w6)\n",
    "w10 = node_op_add(\"w10=w7+w8\", w7,w8)\n",
    "w11 = node_op_add(\"w11=w10+w9\", w10,w9)\n",
    "\n",
    "# computation of output value\n",
    "w12 = node_op_relu(\"w12=relu(w11)\", w11)\n",
    "\n",
    "# teacher value\n",
    "w13 = node(\"w13=teacher value\")\n",
    "\n",
    "# computation of loss\n",
    "w14 = node_op_sub(\"w14=w13-w12\", w13,w12)\n",
    "w15 = node_op_abs(\"w15=abs(w14)\", w14)\n",
    "\n",
    "# add all generated nodes to a Python list\n",
    "all_nodes = [w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15]\n",
    "\n",
    "def feedforward(all_nodes):\n",
    "    \"\"\"\n",
    "    Let all nodes compute their outputs\n",
    "    starting from the first node\n",
    "    and going to the last node in the list\n",
    "    \"\"\"\n",
    "    \n",
    "    for n in all_nodes:\n",
    "        n.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1.value = 2.0\n",
    "w2.value = 1.0\n",
    "w3.value = 1.0\n",
    "w4.value = 10.0\n",
    "\n",
    "feedforward(all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w7.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w11.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w12.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w13.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-20.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w14.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w15.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backpropagation(all_nodes):\n",
    "    \"\"\"    \n",
    "    For each computation node w, compute:\n",
    "    \n",
    "           d loss    d loss         d next_node\n",
    "    _w =   ------ =  ----------- *  ----------- \n",
    "           d w       d next_node    d w\n",
    "                        \n",
    "         = next_node._w * dnext_dw\n",
    "         = (how does the next node change the output?) *\n",
    "           (how does this node change the output of the next node?)\n",
    "          \n",
    "    In other words: do reverse-mode autodiff\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    nr_nodes = len(all_nodes)\n",
    "    \n",
    "    # set seed variable\n",
    "    all_nodes[-1]._w = 1.0\n",
    "    \n",
    "    # go through all nodes, but in reverse order\n",
    "    for w in reversed( all_nodes[0:nr_nodes-1] ):\n",
    "        \n",
    "        # compute how this node\n",
    "        # changes the output of the error node\n",
    "        w._w = 0.0\n",
    "        \n",
    "        # multi-variate chain rule\n",
    "        for next_node in w.is_input_for:\n",
    "            # compute the derivative of the next node\n",
    "            # with respect to node n\n",
    "            dnext_dw = next_node.derive( w )\n",
    "            #print(\"\\tcomputing dnext_dw = d {} / d {} = {}\"\n",
    "            #      .format(next_node.name, w.name, dnext_dw) )\n",
    "            #print(\"\\tnext_node._w = \", next_node._w)\n",
    "            w._w += next_node._w * dnext_dw\n",
    "            \n",
    "        #print(\"computed _{} = {}\".format(w.name, w._w) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "backpropagation(all_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us train a single neuron to learn to add the 3 inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with random start weights and check whether the training procedure correctly sets the weights, such that the outputs are as desired:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 20\n",
      "\t(w4,w5,w6) = (0.2931,1.3372,0.8572)\n",
      "step: 40\n",
      "\t(w4,w5,w6) = (0.3929,1.3603,0.9190)\n",
      "step: 60\n",
      "\t(w4,w5,w6) = (0.4675,1.4101,0.9830)\n",
      "step: 80\n",
      "\t(w4,w5,w6) = (0.5276,1.4054,1.0038)\n",
      "step: 100\n",
      "\t(w4,w5,w6) = (0.5699,1.3952,1.0050)\n",
      "step: 120\n",
      "\t(w4,w5,w6) = (0.6186,1.3756,0.9908)\n",
      "step: 140\n",
      "\t(w4,w5,w6) = (0.6202,1.2970,0.9551)\n",
      "step: 160\n",
      "\t(w4,w5,w6) = (0.6697,1.2805,0.9883)\n",
      "step: 180\n",
      "\t(w4,w5,w6) = (0.7242,1.2583,1.0087)\n",
      "step: 200\n",
      "\t(w4,w5,w6) = (0.7493,1.2411,0.9998)\n",
      "step: 220\n",
      "\t(w4,w5,w6) = (0.7930,1.2107,1.0166)\n",
      "step: 240\n",
      "\t(w4,w5,w6) = (0.8143,1.1762,1.0096)\n",
      "step: 260\n",
      "\t(w4,w5,w6) = (0.8567,1.1513,1.0301)\n",
      "step: 280\n",
      "\t(w4,w5,w6) = (0.8856,1.1295,1.0214)\n",
      "step: 300\n",
      "\t(w4,w5,w6) = (0.9073,1.1026,1.0281)\n",
      "step: 320\n",
      "\t(w4,w5,w6) = (0.9442,1.0655,0.9965)\n",
      "step: 340\n",
      "\t(w4,w5,w6) = (0.9791,1.0417,1.0074)\n",
      "step: 360\n",
      "\t(w4,w5,w6) = (0.9903,1.0052,1.0032)\n",
      "step: 380\n",
      "\t(w4,w5,w6) = (1.0082,1.0009,1.0021)\n",
      "step: 400\n",
      "\t(w4,w5,w6) = (0.9936,1.0093,0.9900)\n",
      "step: 420\n",
      "\t(w4,w5,w6) = (0.9988,0.9981,1.0006)\n",
      "step: 440\n",
      "\t(w4,w5,w6) = (1.0021,0.9866,0.9985)\n",
      "step: 460\n",
      "\t(w4,w5,w6) = (1.0032,0.9955,1.0038)\n",
      "step: 480\n",
      "\t(w4,w5,w6) = (0.9921,1.0012,0.9983)\n",
      "step: 500\n",
      "\t(w4,w5,w6) = (1.0095,1.0016,0.9980)\n",
      "step: 520\n",
      "\t(w4,w5,w6) = (1.0065,1.0063,1.0111)\n",
      "step: 540\n",
      "\t(w4,w5,w6) = (1.0011,0.9914,0.9942)\n",
      "step: 560\n",
      "\t(w4,w5,w6) = (1.0036,1.0119,0.9968)\n",
      "step: 580\n",
      "\t(w4,w5,w6) = (0.9902,0.9952,0.9939)\n",
      "step: 600\n",
      "\t(w4,w5,w6) = (0.9953,0.9954,0.9978)\n",
      "step: 620\n",
      "\t(w4,w5,w6) = (1.0002,0.9969,1.0027)\n",
      "step: 640\n",
      "\t(w4,w5,w6) = (1.0056,0.9944,0.9976)\n",
      "step: 660\n",
      "\t(w4,w5,w6) = (0.9968,1.0030,0.9947)\n",
      "step: 680\n",
      "\t(w4,w5,w6) = (1.0015,0.9893,0.9981)\n",
      "step: 700\n",
      "\t(w4,w5,w6) = (0.9943,1.0000,0.9981)\n",
      "step: 720\n",
      "\t(w4,w5,w6) = (1.0026,0.9900,1.0006)\n",
      "step: 740\n",
      "\t(w4,w5,w6) = (0.9924,1.0089,0.9867)\n",
      "step: 760\n",
      "\t(w4,w5,w6) = (0.9842,0.9973,1.0031)\n",
      "step: 780\n",
      "\t(w4,w5,w6) = (0.9918,0.9980,1.0066)\n",
      "step: 800\n",
      "\t(w4,w5,w6) = (1.0066,1.0030,1.0059)\n",
      "step: 820\n",
      "\t(w4,w5,w6) = (0.9956,0.9937,1.0059)\n",
      "step: 840\n",
      "\t(w4,w5,w6) = (0.9948,0.9987,0.9995)\n",
      "step: 860\n",
      "\t(w4,w5,w6) = (1.0068,0.9983,0.9896)\n",
      "step: 880\n",
      "\t(w4,w5,w6) = (1.0099,0.9984,0.9945)\n",
      "step: 900\n",
      "\t(w4,w5,w6) = (1.0018,0.9916,1.0018)\n",
      "step: 920\n",
      "\t(w4,w5,w6) = (1.0014,1.0029,1.0056)\n",
      "step: 940\n",
      "\t(w4,w5,w6) = (0.9972,1.0046,0.9950)\n",
      "step: 960\n",
      "\t(w4,w5,w6) = (1.0034,1.0092,0.9948)\n",
      "step: 980\n",
      "\t(w4,w5,w6) = (1.0092,1.0090,0.9887)\n",
      "step: 1000\n",
      "\t(w4,w5,w6) = (1.0050,0.9887,1.0005)\n",
      "step: 1020\n",
      "\t(w4,w5,w6) = (1.0035,1.0072,0.9930)\n",
      "step: 1040\n",
      "\t(w4,w5,w6) = (0.9971,1.0022,0.9986)\n",
      "step: 1060\n",
      "\t(w4,w5,w6) = (0.9959,0.9965,1.0017)\n",
      "step: 1080\n",
      "\t(w4,w5,w6) = (0.9938,0.9990,0.9936)\n",
      "step: 1100\n",
      "\t(w4,w5,w6) = (1.0051,1.0063,0.9918)\n",
      "step: 1120\n",
      "\t(w4,w5,w6) = (1.0023,1.0076,0.9981)\n",
      "step: 1140\n",
      "\t(w4,w5,w6) = (1.0008,1.0043,1.0090)\n",
      "step: 1160\n",
      "\t(w4,w5,w6) = (0.9981,0.9982,0.9884)\n",
      "step: 1180\n",
      "\t(w4,w5,w6) = (1.0049,1.0046,0.9997)\n",
      "step: 1200\n",
      "\t(w4,w5,w6) = (0.9998,0.9992,0.9885)\n",
      "step: 1220\n",
      "\t(w4,w5,w6) = (1.0024,0.9885,0.9922)\n",
      "step: 1240\n",
      "\t(w4,w5,w6) = (0.9919,1.0092,1.0041)\n",
      "step: 1260\n",
      "\t(w4,w5,w6) = (0.9967,1.0085,1.0051)\n",
      "step: 1280\n",
      "\t(w4,w5,w6) = (0.9958,1.0052,1.0037)\n",
      "step: 1300\n",
      "\t(w4,w5,w6) = (1.0068,0.9959,1.0039)\n",
      "step: 1320\n",
      "\t(w4,w5,w6) = (0.9952,1.0062,0.9979)\n",
      "step: 1340\n",
      "\t(w4,w5,w6) = (1.0030,0.9953,0.9984)\n",
      "step: 1360\n",
      "\t(w4,w5,w6) = (0.9875,1.0022,0.9885)\n",
      "step: 1380\n",
      "\t(w4,w5,w6) = (1.0007,1.0007,1.0025)\n",
      "step: 1400\n",
      "\t(w4,w5,w6) = (0.9934,1.0019,0.9922)\n",
      "step: 1420\n",
      "\t(w4,w5,w6) = (0.9905,0.9975,1.0050)\n",
      "step: 1440\n",
      "\t(w4,w5,w6) = (0.9973,0.9927,0.9915)\n",
      "step: 1460\n",
      "\t(w4,w5,w6) = (0.9942,0.9998,0.9974)\n",
      "step: 1480\n",
      "\t(w4,w5,w6) = (0.9929,1.0078,0.9879)\n",
      "step: 1500\n",
      "\t(w4,w5,w6) = (0.9924,0.9945,0.9986)\n",
      "step: 1520\n",
      "\t(w4,w5,w6) = (1.0037,1.0001,1.0003)\n",
      "step: 1540\n",
      "\t(w4,w5,w6) = (1.0078,1.0011,1.0091)\n",
      "step: 1560\n",
      "\t(w4,w5,w6) = (0.9934,1.0009,1.0043)\n",
      "step: 1580\n",
      "\t(w4,w5,w6) = (1.0017,0.9964,0.9916)\n",
      "step: 1600\n",
      "\t(w4,w5,w6) = (1.0074,0.9980,0.9990)\n",
      "step: 1620\n",
      "\t(w4,w5,w6) = (0.9923,1.0044,1.0098)\n",
      "step: 1640\n",
      "\t(w4,w5,w6) = (1.0010,0.9963,1.0040)\n",
      "step: 1660\n",
      "\t(w4,w5,w6) = (0.9967,0.9915,1.0000)\n",
      "step: 1680\n",
      "\t(w4,w5,w6) = (1.0045,1.0016,1.0005)\n",
      "step: 1700\n",
      "\t(w4,w5,w6) = (1.0008,1.0041,1.0085)\n",
      "step: 1720\n",
      "\t(w4,w5,w6) = (1.0092,0.9953,0.9941)\n",
      "step: 1740\n",
      "\t(w4,w5,w6) = (0.9946,0.9984,0.9977)\n",
      "step: 1760\n",
      "\t(w4,w5,w6) = (0.9951,0.9944,1.0083)\n",
      "step: 1780\n",
      "\t(w4,w5,w6) = (1.0022,0.9928,0.9905)\n",
      "step: 1800\n",
      "\t(w4,w5,w6) = (1.0008,1.0040,1.0000)\n",
      "step: 1820\n",
      "\t(w4,w5,w6) = (0.9965,1.0073,1.0124)\n",
      "step: 1840\n",
      "\t(w4,w5,w6) = (0.9925,0.9972,0.9952)\n",
      "step: 1860\n",
      "\t(w4,w5,w6) = (1.0036,0.9956,1.0010)\n",
      "step: 1880\n",
      "\t(w4,w5,w6) = (0.9938,1.0029,0.9993)\n",
      "step: 1900\n",
      "\t(w4,w5,w6) = (0.9985,0.9946,0.9972)\n",
      "step: 1920\n",
      "\t(w4,w5,w6) = (1.0059,1.0013,0.9973)\n",
      "step: 1940\n",
      "\t(w4,w5,w6) = (1.0038,0.9879,1.0020)\n",
      "step: 1960\n",
      "\t(w4,w5,w6) = (0.9915,0.9987,0.9989)\n",
      "step: 1980\n",
      "\t(w4,w5,w6) = (0.9947,1.0073,1.0009)\n",
      "step: 2000\n",
      "\t(w4,w5,w6) = (1.0060,0.9901,0.9941)\n"
     ]
    }
   ],
   "source": [
    "from random import random\n",
    "import numpy as np\n",
    "\n",
    "# set start weights\n",
    "w4.value = 0.2\n",
    "w5.value = 1.3\n",
    "w6.value = 0.8\n",
    "\n",
    "show_debug_info = False\n",
    "learn_rate = 0.01\n",
    "steps = 2000\n",
    "errors = []\n",
    "for step in range(1,steps+1):\n",
    "    \n",
    "    if show_debug_info:\n",
    "        print(\"step:\", step)\n",
    "    else:\n",
    "        if step % (steps/100) == 0:\n",
    "            print(\"step:\", step)\n",
    "            print(\"\\t(w4,w5,w6) = ({:.4f},{:.4f},{:.4f})\"\n",
    "                  .format(w4.value, w5.value, w6.value) )\n",
    "        \n",
    "    \n",
    "    # 1. randomly generate 3 input values\n",
    "    w1.value = random()\n",
    "    w2.value = random()\n",
    "    w3.value = random()\n",
    "    if show_debug_info:\n",
    "        print(\"\\tinput vec: ({0:.2},{1:.2},{2:.2})\"\n",
    "              .format(w1.value,w2.value,w3.value))\n",
    "    \n",
    "    # 2. compute and set teacher value\n",
    "    w13.value = w1.value + w2.value + w3.value # test function 1\n",
    "    #w13.value = w1.value + 2.0*w2.value + 3.0*w3.value # test function 2\n",
    "    #w13.value = w1.value # test function 3\n",
    "    #w13.value = w1.value+w3.value # test function 4\n",
    "    #w13.value = w1.value*w1.value # test function 5\n",
    "    \n",
    "    # 3. forward propagation\n",
    "    feedforward(all_nodes)\n",
    "    \n",
    "    # 4. compare actual output with teacher value\n",
    "    if show_debug_info:\n",
    "        print(\"\\tis: {0:.2} vs. teacher: {1:.2}\"\n",
    "              .format(w12.value, w13.value))\n",
    "    \n",
    "    # 5. train (adapt) weights?\n",
    "    if True:\n",
    "            \n",
    "        # 5.1 compute gradient\n",
    "        backpropagation(all_nodes)\n",
    "        \n",
    "        # 5.2 show gradient\n",
    "        if show_debug_info:\n",
    "            print(\"\\tThe gradient is: ({:.2f},{:.2f},{:.2f})\"\n",
    "                  .format(w4._w, w5._w, w6._w) )\n",
    "        \n",
    "        # 5.3 adapt weights\n",
    "        w4.value += learn_rate * -w4._w\n",
    "        w5.value += learn_rate * -w5._w\n",
    "        w6.value += learn_rate * -w6._w\n",
    "            \n",
    "    # 6. compute error and store it in a list\n",
    "    error = abs(w12.value - w13.value)\n",
    "    errors.append( error )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYVOWZ/vHv0w3NKjTQzQ4CghJUcOmgMa6XG7iE0RiD\nmsXJ5Ef8RRMzmTFBHTOZmElc4iQmaggSx8SoaBKMRFEMiiIiSIsoOzR7N1uzNtD0/swfVbTVa1U3\ntfQp7s919WWd97x1zuPp4u633jp1jrk7IiKSXjJSXYCIiMSfwl1EJA0p3EVE0pDCXUQkDSncRUTS\nkMJdRCQNKdxFRNKQwl1EJA0p3EVE0lC7VO04JyfHhwwZkqrdi4gE0ocffrjb3XOj9UtZuA8ZMoT8\n/PxU7V5EJJDMbHMs/TQtIyKShhTuIiJpSOEuIpKGFO4iImlI4S4ikoYU7iIiaUjhLiKShmIKdzMb\nZ2ZrzKzAzCY3sv4uM1sa/lluZtVm1jP+5X5q3c6DfLBxbyJ3ISISWFHD3cwygceB8cAo4CYzGxXZ\nx90fdvcz3P0M4G7gHXdPaPJe/st53Pi79xO5CxGRwIpl5D4WKHD3De5eAUwHJjTT/ybg+XgUJyIi\nrRNLuA8AtkYsF4bbGjCzzsA44K/HXpqIiLRWvD9QvRZ4r6kpGTObZGb5ZpZfXFwc512LiMhRsYR7\nETAoYnlguK0xE2lmSsbdp7p7nrvn5eZGvaiZiIi0UizhvhgYYWZDzSyLUIDPrN/JzLoDFwEvx7dE\nERFpqaiX/HX3KjO7A5gNZAJPufsKM7stvH5KuOt1wBvufjhh1Ya9V7A70bsQEQm0mK7n7u6zgFn1\n2qbUW34aeDpehTWltKKKW6YtSvRuREQCLXDfUK2q8VSXICLS5gUu3DPMUl2CiEibF7hwrx/tW/eW\npqQOEZG2LHDhXt9v31mf6hJERNqcwIV7/VmZDM3SiIg0ELxwrzcxk6k5eBGRBgIX7vWZwl1EpIHA\nh7vOnhERaSgNwj3VFYiItD2BD/dp8zfyzlpdYVJEJFLgwt1p+A3VJ+dtSEElIiJtV+DCvTGNBb6I\nyPEsPcLdYUHBbtbuPJjqUkRE2oSYrgrZlngTg/Sbw1eK3PTA1UmsRkSkbUqLkbuIiNSVFuHe1Ghe\nROR4lRbhLiIidQUu3DVIFxGJLnDh3hidCikiUldM4W5m48xsjZkVmNnkJvpcbGZLzWyFmb0T3zJF\nRKQlop4KaWaZwOPA5UAhsNjMZrr7yog+2cATwDh332JmvRNVsIiIRBfLyH0sUODuG9y9ApgOTKjX\n52ZghrtvAXD3XfEt81PeyKkxOltGRKSuWMJ9ALA1Yrkw3BbpZKCHmb1tZh+a2dfiVaCIiLRcvL6h\n2g44G7gU6AS8b2YL3X1tZCczmwRMAhg8eHCcdq0zaERE6otl5F4EDIpYHhhui1QIzHb3w+6+G5gH\njKm/IXef6u557p6Xm5vbqoIV5CIi0cUS7ouBEWY21MyygInAzHp9XgbON7N2ZtYZOAdYFd9SRUQk\nVlGnZdy9yszuAGYDmcBT7r7CzG4Lr5/i7qvM7HXgE6AGmObuyxNZeKRt+48ka1ciIoEQ05y7u88C\nZtVrm1Jv+WHg4fiVFrvCfQp3EZFIgfuGqk57FBGJLnDhLiIi0SncRUTSkMJdRCQNBS/cNecuIhJV\n8MJdRESiUriLiKShwIW7bswhIhJd4MJdRESiU7iLiKQhhbuISBoKXLjr8gMiItEFLtxFRCQ6hbuI\nSBpSuIuIpKHAhbum3EVEogtcuIuISHQKdxGRNBS4cHedCykiElVM4W5m48xsjZkVmNnkRtZfbGYH\nzGxp+OdH8S9VRERiFfUG2WaWCTwOXA4UAovNbKa7r6zX9V13vyYBNYqISAvFMnIfCxS4+wZ3rwCm\nAxMSW5aIiByLWMJ9ALA1Yrkw3FbfeWb2iZm9ZmanxqW6RmjGXUQkuqjTMjFaAgx290NmdhXwN2BE\n/U5mNgmYBDB48OA47VpEROqLZeReBAyKWB4Ybqvl7iXufij8eBbQ3sxy6m/I3ae6e5675+Xm5h5D\n2SIi0pxYwn0xMMLMhppZFjARmBnZwcz6mpmFH48Nb3dPvIsFXRVSRCQWUadl3L3KzO4AZgOZwFPu\nvsLMbguvnwLcAPx/M6sCjgATXSeki4ikTExz7uGplln12qZEPH4MeCy+pYmISGsF7huq0bz6yXYq\nqmpSXYaISEoFLtw9ysmQtz+3hEf+sSZJ1YiItE2BC/dY7DhQluoSRERSKi3DXUTkeJeW4W6pLkBE\nJMWCF+46wVJEJKrghbuIiESlcBcRSUOBC3fNyoiIRBe4cI9F+DI3IiLHrbQMdxGR453CXUQkDQUu\n3HWtSRGR6AIX7iIiEp3CXUQkDaVluOtcGRE53gUu3KNd8ldERAIY7iIiEp3CXUQkDcUU7mY2zszW\nmFmBmU1upt9nzazKzG6IX4l1xXoq5Pvr9/Bewe5ElSEi0qZFDXczywQeB8YDo4CbzGxUE/0eBN6I\nd5EtZnDTkwu5ZdqiVFciIpISsYzcxwIF7r7B3SuA6cCERvp9B/grsCuO9YmISCvEEu4DgK0Ry4Xh\ntlpmNgC4Dvhtcxsys0lmlm9m+cXFxS2tNWYVVTUJ27aISBDE6wPVXwE/dPdmU9Xdp7p7nrvn5ebm\ntmpHsUy5l5RVtWrbIiLpol0MfYqAQRHLA8NtkfKA6eFL7eYAV5lZlbv/LS5ViohIi8QS7ouBEWY2\nlFCoTwRujuzg7kOPPjazp4FXUhnsrquLichxLmq4u3uVmd0BzAYygafcfYWZ3RZePyXBNYqISAvF\nMnLH3WcBs+q1NRrq7n7rsZfVbC2J3LyISFpIy2+oRrvN3n1/W84P/vJxkqoREUm+tAz3aKP7ZxZu\n5sX8wiRVIyKSfIELd83KiIhEF7hwf3uNvgArIhJN4MK9tKI61SWIiLR5gQv3KJ+ViogIAQz3WLy7\nTpf6FZHjW1qGu4jI8S5w4W66/bWISFSBC3cREYlO4S4ikoYCF+46W0ZEJLrAhbuIiESncBcRSUMK\ndxGRNBS4cI92OV8REQliuKe6ABGRAAhcuCfCy0uLeOC11akuQ0QkbhTuwJ3TlzLlnfWpLkNEJG5i\nCnczG2dma8yswMwmN7J+gpl9YmZLzSzfzM6Pf6lH95WoLYuIpI+oN8g2s0zgceByoBBYbGYz3X1l\nRLc3gZnu7mY2GngRGJmIgkVEJLpYRu5jgQJ33+DuFcB0YEJkB3c/5J/euLQLoJvhiYikUCzhPgDY\nGrFcGG6rw8yuM7PVwKvANxrbkJlNCk/b5BcXF7emXp0tIyISg7h9oOruL7n7SOCfgPub6DPV3fPc\nPS83N7dV+2nNee6rd5Qwd80u3l+/p077c4u2tKoGEZG2LuqcO1AEDIpYHhhua5S7zzOzYWaW4+4p\nvyVSaUUV4371bu3y6vvH1T6+56Vl3HzO4FSUJSKSULGM3BcDI8xsqJllAROBmZEdzGy4hYfUZnYW\n0AHY02BLKbDnUEWd5Rpv+uOAskrdfFtE0kPUcHf3KuAOYDawCnjR3VeY2W1mdlu42xeB5Wa2lNCZ\nNV+O+IA1ro71VMin5m9sct3I+15vMHUjIhJEsUzL4O6zgFn12qZEPH4QeDC+pTXuWD9Q/cUba+ss\nL9myr87yoo17+NxJvY5xLyIiqXXcf0P1+icW1Fmu0UmcIpIGjvtwry9Bs0kiIkkVvHBP8PUHmvvA\nVUQkKIIX7i1U1cJ5Fk3LiEg6SPtwv/KX81rUXyN3EUkHgQv3lk7KVFTXtKi/sl1E0kHwwj3BF5ep\n0byMiKSBwIV7oinbRSQdKNzr0Zy7iKSDwIW7JfiivzrPXUTSQfDCPdFz7sp2EUkDgQv3RHtm4WYO\nllU2um7LnlL2l1Y0uk5EpC1RuDfiodfXNNp+4cNzufgXbye3GBGRVghcuCfjNntHmrmu+/7Sxkf1\nIiJtSeDCXUREolO4i4ikocCFe6LPloHkTP2IiCRSTHdiaksSfZ47QP2zIQv3lfLsoi0J36+ISLwE\nLtxT4fbnPuLjrftTXYaISMximpYxs3FmtsbMCsxsciPrbzGzT8xsmZktMLMx8S81eQy456VlvLy0\nCICKqpZdWVJEJNWihruZZQKPA+OBUcBNZjaqXreNwEXufjpwPzA13oV+WlDCtlzHc4u2cOf0pboc\ngYgEUiwj97FAgbtvcPcKYDowIbKDuy9w933hxYXAwPiWmTqzV+xMdQkiIi0WS7gPALZGLBeG25ry\nL8Brja0ws0lmlm9m+cXFxbFXGbmNVj2r9fYcLtfoXUQCJ66nQprZJYTC/YeNrXf3qe6e5+55ubm5\n8dx1wjR3dk5ZZTV/WrhZ4S8ibU4sZ8sUAYMilgeG2+ows9HANGC8u++JT3kNWTJOdI8w7d0NZLWr\n+zewrLKa5z/YQuG+I/x+/kZyumYx7rR+Sa1LRKQ5sYT7YmCEmQ0lFOoTgZsjO5jZYGAG8FV3Xxv3\nKlNow+7DjOx7Qp2237y1jsfnrq/9QtWh8qavRSMikgpRw93dq8zsDmA2kAk85e4rzOy28PopwI+A\nXsAT4ZF1lbvnJa7s5Ko/63LgSGWj7SIibUVMX2Jy91nArHptUyIefxP4ZnxLa1wyJmV2Hiyvs+z1\nvrO6aXdp3fVKeRFpY3RtmUbMW9v8mTzzC3YnvggRkWMQuHAfMyg71SU0kOwPeUVEoglcuJ+U2zXp\n+9Ssi4gETeDCvS3SnLuItDUK9xgoukUkaBTuIiJpSOEeA027iEjQKNzjQGfLiEhbo3CPA43sRaSt\nUbjHQNEtIkGjcBcRSUMK91ho6C4iAaNwFxFJQwr3GGjgLiJBo3CPQY3OhhGRgFG4xyDWcC/af4Qh\nk19ledGBBFckItI8hXsMamqaX19d4/z7nz/m8w+8BcBzH2xJQlUiIk2L6U5Mx7toX1KaPGNZvf6J\nrEZEJLqYRu5mNs7M1phZgZlNbmT9SDN738zKzezf419mam07UNbCZyjdRSS1oo7czSwTeBy4HCgE\nFpvZTHdfGdFtL/Bd4J8SUmXAaOQuIqkWy8h9LFDg7hvcvQKYDkyI7ODuu9x9MVCZgBoDZ/rirdz/\nysroHUVEEiSWcB8AbI1YLgy3STN+P39jqksQkeNYUs+WMbNJZpZvZvnFxcVx2mZcNpNwuw6WkffT\nOazdeTDVpYjIcSCWcC8CBkUsDwy3tZi7T3X3PHfPy83Nbc0mGghItvOPlTvZfaic/31vU6pLEZHj\nQCzhvhgYYWZDzSwLmAjMTGxZsdONMkREGop6toy7V5nZHcBsIBN4yt1XmNlt4fVTzKwvkA90A2rM\n7HvAKHcvSWDtQHBG7iIiyRTTl5jcfRYwq17blIjHOwhN1yRd8AbuOk9SRBIv8JcfMI3dRUQaCP7l\nBwKQ7T+ftYrfzduQ6jJE5DgS+JF7RgDCXcEuIskW+HAP4rSMu/OnhZs5XF6V6lJEJE0FPtzb8sh9\nedEBCveV1mkrOVLFewV7+I+/Lecnf9clCkQkMQI/596Wz3O/5jfzG7S9umw7ZwzKBmDP4YpklyQi\nx4nAj9zbbrQ37b9nrUp1CSKS5gIf7oFMdxGRBAtkuF9/1qcXpcxow9MyIiKpEshw79+9U+1jZbuI\nSEOBDPfqiFsdKdtFRBoKZLh/Oe/TKxC39myZtnAK5ZxVO1NdgoikqUCG+5CcLiy+9zKg9SP3zw/P\niV9BIiJtTCDDHcDDV1ds7cj9JxNOi2c5rfaL2Wtw3VFbROIssOHetUPo+1dfymvdlYaH5nTh0pG9\n41lSqzw2t4Ate0ujdxQRaYHAhnvnrHasvn8cd11xCh//6IpWbaNdZmjU/9tbzmJk3xPqrLvuzOTd\nA/yih99mqwJeROIosOEO0LF9JhkZRvfO7RnVr1uLn98+M/S/X1nz6bTIkF6dATi5zwmNPqcl+nfv\nGHPfxi5VcLzYWVLW6B+3A0cqWVCwu9nn7jtcwfx1zfcRqK7xpE//7T1cwfKiA0ndZ30Pz17N4k17\nY+q793AFu0rKWr2vQ+VVbWqQFuhwj3R0FN4SteFeVUPPLlkADMvtCsTn/PlLWjDtc+BIZcwvwkiz\nlm2Pyz+gnSVl3PHcEkorWnalSnensrrmmPZ9zs/e5IKH5lJWWc3jcwuoqApt71vP5HPztEXc89Ky\n2r5f/f0ipryzvnb5m3/M5yu/X9TiuuOtpsaZsaSQquoadpWU8dqy7ce0vbmrd7Fg/W7+sGATizbs\nabC+rLKaov1HqKiqYV8T1yiqrK7hibcLKKus5qR7ZvGNpxfz/ReWUlJWWdvnw817+dWctcdUa1Ou\ne+I9rvnNfH48c0XUPyxHKqp5dM662tfS9gNHmu2//cARrvzlPHYcCIXxxt2HeXTOugb7eXzuer40\n5f3a5V/NWcvMj7cBodfuofIqDoWvznrW/f9g7M/ebNn/ZISJU9/ngofm1mmrrK7hq79fxJIt+wB4\ndtHmBhcTTJTAXzjsqN/cdCbT3t3IMws3x/ycduHzIatqavj1TWfy2rLtbNlbylur43P+fGYLz7f8\n0pT3+dvtn6+9sFhFVQ37Sis4WFbF8N5dG33Ot59dAsCmB66ubVu6dT89OrfnxF5dqK5x/vj+Jm4a\nO5h2Gcbba4q59DO9MTP2HCqntKKazlmZ3D1jGW+t3sXw3l353mUn19nHgoLdZGQY5w7rVds26kev\nM/60fgzs0YlH31zHqp+Mo2P7DB6evYYdJWU88qUxTX7YXV5VjWFktas7tnjo9TU89d5GumRlcvrA\nbBZuCP2xe27RFiaPH8krH2/n3XW7eXfdbm676CQACnYdAkKjpj8s2Mz40/oyJKdLne2+v34PNz25\nkA/uuZSOWZkcLKuiutrpl92x9g88wCufbGNYTlfaZRpF+4+weONePj88h3OH9aK8qprOWU3/c/nb\n0iK+/+LH7Cwp5+WlRazecZBVPxlHp6zM2j57DpXz0kdFXPqZPvz3qyuZs2oXi+65lD7d6r7DO1JR\nzT8/vbhO29Hf7+Y9h7no4bdr268Y1Yc3Vu5k/c+uavB6ezF/Kw+9vobyylBgzl1TDMDK7SWs3nGQ\n/t07si0cjiP7dqO0oorrzwp9hvX68u3c/8oq3r7rYtpnZlBSVkmGGV07tONgWSU/fWUVd142gv7Z\nnfhg416K9pdyWv/u9OnekdE/fqNOHU8v2MQPx42kU1Ym097dQL/unbh6dL8623xs7joen7ue3t06\nMCC7E1976oPa579z18UcLq/m5D5daRf+fV316LvsK63k3J+/yVO35vFff1/J5j2ljOrfjQtG5NCx\nfSY1NQ3/oPxqzjoAep/QgYlTFzY4vgBb95bSvXN7Hp2zjjsvG8HKbSVMnbeBJ7+WxyufbOOcob3o\nG35XXlVdgxMaKC4vCt0y+tvPfsgTt5zN5j2HKa+q4d11u3mvYDdL7ruce19azrDcLrz1bxc3qC3e\nLJa3amY2DniU0A2yp7n7A/XWW3j9VUApcKu7L2lum3l5eZ6fn9/aups0ZPKrALww6Vy+PHUhL37r\nc9z+3BKKD5bX6bfpgavZureU707/iKdvHUv3zu0B+OkrK5k2fyP3XDWS8af1o1NWJmt2HOSWaYta\nXMut5w3h6QWbWvy8b100jAHZnfjRyytq2/71spP55Zy1XDumP/92+ckMyelCeVU1p/zH6wB8dN/l\ndMrK5E8LN/PTV0MXJnvya3kcLq/iey8srbP93331bLbvP8KPm7jk8K3nDeHaMf0oOVJFlw7tuPF3\noZHP1af3o1un9jz/wZbavr26ZDV6dcvbLjqJ0QO706VDOz5/Ui8e+cdafvv2er5/+cn8zz/WMrhn\nZx65cUydUdVR2Z3bs7+0skF7fT+//nTunhEa1Y8Z2J2PCw8wILsTpw3oxvriw/zntaP4zVsF7DhQ\n1uSH1uNO7cuki4Zx/RMLmtzPOUN7smjjXn755THsPVzJk/M2cPaJPVi0cS/lldXcc/Vn+PWb69h+\noIyTcruwvvgwAHO+fyEn9urCym0lZGZYo1NvXzl3MD8YN5Lyyho27j7M2KE9mTpvPT+btbpOv9X3\nj6Nj+8za13djJl04jLMGZ/P54Tm8sHhr7evgvJN6sWB9w9F/Yx750hi27C3lsbkFVDcSjpEG9ezE\na3deyGn/Obu27bNDerB4074GfRffexk7S8pqj8HJfbqydmfoD/PXP3ciAH94PzQwu+WcwTy7aEuD\nbRz10A2j+cFfPmlyfU7XDlwzuh/z1hWzIfy7APjupSP49ZvrGn3OE7ecVTtQgtBnbi99VNTkPi4d\n2Zv5Bbspr6ohq10G//WFU2tfiwBnDc5myZb9dZ7zrYuG8bt3Qjfu+ei+y+kRni1oKTP70N3zovaL\nFu5mlgmsBS4HCoHFwE3uvjKiz1XAdwiF+znAo+5+TnPbTXS4R/4lnvD4e3y8te6Bjlwfafehcib/\ndRmP3DiG7p3aN9juXVeewsOz19R5ztihPflgY8MplbvHj+Tnr61u0C7SlBnfPq/ZPzSSHi77TB+m\nfT1qPjcq1nCPZc59LFDg7hvcvQKYDkyo12cC8EcPWQhkm1m/FlcdBw9cfzr3XTOqTtsXz4r9zJec\nrh2Y9vW8OsF+VM8uWdx+yXCW3Hc5J+V++tZ/+v87l9X3j2vQ/5sXDGtB5SIo2I8TyfjgNZY59wHA\n1ojlQkKj82h9BgDH9qlSK0wcO7hB21fPPZFbzjmRvy4pbPbtXHNemHRu7Vxuzy5ZzLrzAv7z5RWc\nPyKHjAyjY0Ym8394CT06Z/Hsos3cmDeIzAxjaE4XNu4OvTW86ORc7rvmMxTsOsxtf/oQgB+OG8mD\nr2t0L3I8ufmchjkVb7FMy9wAjHP3b4aXvwqc4+53RPR5BXjA3eeHl98Efuju+fW2NQmYBDB48OCz\nN2+O/cPPeFm5rYTdh8q58OTcpOzvSEU1764r5sX8Qh66YXTtWTnVNU6GffoN25oa55mFm8kwuPiU\n3sxYUsRLHxVy2oDuvPLJdh64/nSG5nTh12+tY/xp/ThjUDbdO7WnS4d2VFTVsKzoAMsK9/PZoT3J\nzDD2Ha7kYFklP39tNa9+93x2lpTx8Ow1DOrRmTmrdtKhXSY7wqd9vfGvF/L3j7exYlsJK7Yd4IpR\nfblr3Cm8tKSIK07tw9PvbeLCk3O5688fc+2Y/px9Yg9eXbadC0bk0vuEDowe2J1fv1lAu0yjYNch\n9hwq55S+J3DdmQPZdbCMrMwMunVqz6rtJRw4Usn2A2VUVtcwuGdnenXJoryqhi+c0Z8/vr+ZJZv3\ncVLvrow/rS/TP9jKq8u2c83ofpx9Yg96n9CRpxds5Atj+vP0gk1kZhgd22eyv7SSzw7pyYAencCd\n80fk8szCzXRsl8EXzujPL95Yy7nDenLhiFyeXbSZDu0yufLUvryztpgdB44wemA2F5+SS68uHejZ\nNYt//t8PqKx2rjq9LwvW7+GhG0Yz5e0NjB3ag+zOWew4UEZZZTWTZyzjjkuGc3LfE8jKNB59s4Az\nBmUzv6CYa0b3p/cJHRg7tCfPf7CFL541kLdW7+LiU3ozpFdnNu8t5c/5W7l2dH+WFu7nps8OZuGG\nPSwrOkBZZQ017vTqkkWvrh3Yuq+UkX1PYO7qXaF3lvM3AqHPQF5dtp1LR/amvKqG84b3YnhuV3p1\nzaL4YDlLtuznghE5LN64l637jtApK5OSI6FjdfEpuZRWVLNg/R5O7d8NA/pnd6Jbp/bMWFLIim0l\nrN15kEtO6U3f7h3JNOMvHxay7cAR/vCNsQzI7sSRimrufGEpEz87iOzO7cnulMWh8iq+/eyHVNU4\nYwZmc8agbPaXVpDTtQMTzhjAXz7cSnl1DXeP/wzvritmaE4XBmR3YtayHZx1YjbLCg9wz0vL+VLe\nQGpqnPOG53DGoGw6Z2Vyz4xl3H7JcDq0z2DyX5dxqLyKh24YzbR3N7LjwBHuvXoUL+ZvZeyQnnzz\nj/nccclwKqtrOCm3K8P7dOWxtwq48tQ+nD4gm4LiQ1w6sjeTZyxjZN8TuO7MAXzn+Y9on2kM7tmZ\nC0bksmjjHl5fvoMHvzia3YfKObV/d9buPMjBsio2FB+i2p0rRvVl7c6DnDm4Bx3aZXDNb+bzvctG\ncGPeIPYeruB/39vEiD5d6d6pPaf278ary7YzMLsTXzn3xFZ/uz6ec+6fA37s7leGl+8GcPefR/T5\nHfC2uz8fXl4DXOzuTY7cEzXnLiKSzuI5574YGGFmQ80sC5gIzKzXZybwNQs5FzjQXLCLiEhiRZ1z\nd/cqM7sDmE3oVMin3H2Fmd0WXj8FmEXoTJkCQqdC/nPiShYRkWhi+hKTu88iFOCRbVMiHjtwe3xL\nExGR1kqbyw+IiMinFO4iImlI4S4ikoYU7iIiaUjhLiKShmK6KmRCdmxWDLT2K6o5QFu8Q0NbrQva\nbm2qq2VUV8ukY10nunvUr9inLNyPhZnlx/INrWRrq3VB261NdbWM6mqZ47kuTcuIiKQhhbuISBoK\narhPTXUBTWirdUHbrU11tYzqapnjtq5AzrmLiEjzgjpyFxGRZgQu3M1snJmtMbMCM5uc5H0PMrO5\nZrbSzFaY2Z3h9h+bWZGZLQ3/XBXxnLvDta4xsysTWNsmM1sW3n9+uK2nmf3DzNaF/9sjmXWZ2SkR\nx2SpmZWY2fdScbzM7Ckz22VmyyPaWnx8zOzs8HEuMLNfW2vvuNB8XQ+b2Woz+8TMXjKz7HD7EDM7\nEnHcpkQ8Jxl1tfj3lqS6XoioaZOZLQ23J/N4NZUNqXuNuXtgfghdcng9MAzIAj4GRiVx//2As8KP\nTyB04/BRwI+Bf2+k/6hwjR2AoeHaMxNU2yYgp17bQ8Dk8OPJwIPJrqve724HcGIqjhdwIXAWsPxY\njg/wAXAuYMBrwPgE1HUF0C78+MGIuoZE9qu3nWTU1eLfWzLqqrf+EeBHKTheTWVDyl5jQRu5x3Kz\n7oRx9+3uviT8+CCwitC9YpsyAZju7uXuvpHQ9e7HJr7SOvv/Q/jxH4B/SmFdlwLr3b25L64lrC53\nnwfsbWR9jIodAAAC9klEQVR/MR8fC930vZu7L/TQv8I/RjwnbnW5+xvuXhVeXAgMbG4byaqrGSk9\nXkeFR7g3As83t40E1dVUNqTsNRa0cG/qRtxJZ2ZDgDOBReGm74TfRj8V8dYrmfU6MMfMPrTQvWoB\n+vind8TaAfRJQV1HTaTuP7pUHy9o+fEZEH6crPoAvkFo9HbU0PAUwztmdkG4LZl1teT3luzjdQGw\n093XRbQl/XjVy4aUvcaCFu5tgpl1Bf4KfM/dS4DfEpoqOgPYTuitYbKd7+5nAOOB283swsiV4VFA\nSk6NstDtGb8A/Dnc1BaOVx2pPD5NMbN7gSrg2XDTdmBw+Pf8feA5M+uWxJLa3O+tnpuoO4BI+vFq\nJBtqJfs1FrRwLwIGRSwPDLcljZm1J/TLe9bdZwC4+053r3b3GuBJPp1KSFq97l4U/u8u4KVwDTvD\nb/OOvhXdley6wsYDS9x9Z7jGlB+vsJYenyLqTpEkrD4zuxW4BrglHAqE38LvCT/+kNA87cnJqqsV\nv7dkHq92wPXACxH1JvV4NZYNpPA1FrRwj+Vm3QkTntP7PbDK3f8nor1fRLfrgKOf5M8EJppZBzMb\nCowg9GFJvOvqYmYnHH1M6AO55eH9fz3c7evAy8msK0KdEVWqj1eEFh2f8NvrEjM7N/xa+FrEc+LG\nzMYBPwC+4O6lEe25ZpYZfjwsXNeGJNbVot9bsuoKuwxY7e61UxrJPF5NZQOpfI0dyyfEqfghdCPu\ntYT+Ct+b5H2fT+ht1SfA0vDPVcAzwLJw+0ygX8Rz7g3XuoZj/ES+mbqGEfrk/WNgxdHjAvQC3gTW\nAXOAnsmsK7yfLsAeoHtEW9KPF6E/LtuBSkLzmP/SmuMD5BEKtfXAY4S/CBjnugoIzccefY1NCff9\nYvj3uxRYAlyb5Lpa/HtLRl3h9qeB2+r1TebxaiobUvYa0zdURUTSUNCmZUREJAYKdxGRNKRwFxFJ\nQwp3EZE0pHAXEUlDCncRkTSkcBcRSUMKdxGRNPR/izirb0mSal8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2de8de77d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
