{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Classes-for-building-up-a-computation-graph\" data-toc-modified-id=\"Classes-for-building-up-a-computation-graph-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Classes for building up a computation graph</a></span></li><li><span><a href=\"#Building-up-a-simple-computation-graph:-a-single-neuron\" data-toc-modified-id=\"Building-up-a-simple-computation-graph:-a-single-neuron-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Building up a simple computation graph: a single neuron</a></span></li><li><span><a href=\"#Implementing-Backpropagation\" data-toc-modified-id=\"Implementing-Backpropagation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Implementing Backpropagation</a></span></li><li><span><a href=\"#Let-us-train-a-single-neuron-to-learn-to-add-the-3-inputs\" data-toc-modified-id=\"Let-us-train-a-single-neuron-to-learn-to-add-the-3-inputs-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Let us train a single neuron to learn to add the 3 inputs</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "MiniFlow is not TensorFlow.\n",
    "\n",
    "It is a very minimalistic framework with the goal to introduce students into the idea of\n",
    "- representing a neural network as a computation graph\n",
    "- computing the gradient of the error function with respect to the model parameters by using Reverse-mode autodiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classes for building up a computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class node:\n",
    "    \"\"\"\n",
    "    A graph node can just store a value\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.value = 0.0\n",
    "        self._w = 0.0\n",
    "        self.is_input_for = []\n",
    "        \n",
    "    def compute(self):\n",
    "        pass\n",
    "    \n",
    "    def derive(self, w):\n",
    "        pass\n",
    "        \n",
    "\n",
    "\n",
    "class node_op_unary(node):\n",
    "    \"\"\"\n",
    "    Base class for unary operation nodes,\n",
    "    e.g. Relu(x), abs(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name, input1):\n",
    "        node.__init__(self, name)\n",
    "        self.input1 = input1\n",
    "        input1.is_input_for.append( self )\n",
    "\n",
    "        \n",
    "\n",
    "class node_op_binary(node):\n",
    "    \"\"\"\n",
    "    Base class for binary operation nodes,\n",
    "    e.g. x*y, x+y, x-y\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name, input1, input2):\n",
    "        node.__init__(self, name)\n",
    "        self.input1 = input1\n",
    "        self.input2 = input2\n",
    "        input1.is_input_for.append( self )\n",
    "        input2.is_input_for.append( self )\n",
    "\n",
    "\n",
    "        \n",
    "class node_op_mult(node_op_binary):\n",
    "    \"\"\"\n",
    "    x*y\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name, input1, input2):\n",
    "        node_op_binary.__init__(self, name, input1, input2)\n",
    "    \n",
    "    def compute(self):\n",
    "        self.value = self.input1.value * self.input2.value\n",
    "        \n",
    "    def derive(self, w):\n",
    "        \"\"\"\n",
    "        compute the derivative of this node\n",
    "        with respect to node <w>\n",
    "        \"\"\"\n",
    "        if w==self.input1:\n",
    "            return self.input2.value\n",
    "        elif w==self.input2:\n",
    "            return self.input1.value\n",
    "        \n",
    "\n",
    "        \n",
    "class node_op_add(node_op_binary):\n",
    "    \"\"\"\n",
    "    x+y\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name, input1, input2):\n",
    "        node_op_binary.__init__(self, name, input1, input2)\n",
    "    \n",
    "    def compute(self):\n",
    "        self.value = self.input1.value + self.input2.value\n",
    "        \n",
    "    def derive(self, w):\n",
    "        \"\"\"\n",
    "        compute the derivative of this node\n",
    "        with respect to node <w>\n",
    "        \"\"\"\n",
    "        if w == self.input1:\n",
    "            return 1.0\n",
    "        elif w == self.input2:\n",
    "            return +1.0\n",
    "        \n",
    "\n",
    "        \n",
    "class node_op_sub(node_op_binary):\n",
    "    \"\"\"\n",
    "    x-y\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name, input1, input2):\n",
    "        node_op_binary.__init__(self, name, input1, input2)\n",
    "    \n",
    "    def compute(self):\n",
    "        self.value = self.input1.value - self.input2.value  \n",
    "        \n",
    "    def derive(self, w):\n",
    "        \"\"\"\n",
    "        compute the derivative of this node\n",
    "        with respect to node <w>\n",
    "        \"\"\"\n",
    "        if w == self.input1:\n",
    "            return 1.0\n",
    "        elif w == self.input2:\n",
    "            return -1.0\n",
    "        \n",
    "\n",
    "        \n",
    "class node_op_relu(node_op_unary):\n",
    "    \"\"\"\n",
    "    Relu(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name, input1):\n",
    "        node_op_unary.__init__(self, name, input1)\n",
    "        \n",
    "    def compute(self):\n",
    "        \"\"\"\n",
    "        compute output of this node: Relu(input)\n",
    "        \"\"\"\n",
    "        if self.input1.value < 0.0:\n",
    "            self.value = 0.0\n",
    "        else:\n",
    "            self.value = self.input1.value\n",
    "            \n",
    "            \n",
    "    def derive(self, w):\n",
    "        \"\"\"\n",
    "        compute the derivative of this node\n",
    "        with respect to node <w>\n",
    "        \"\"\"\n",
    "        if w.value < 0.0:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return 1.0\n",
    "            \n",
    "\n",
    "            \n",
    "class node_op_abs(node_op_unary):\n",
    "    \"\"\"\n",
    "    abs(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name, input1):\n",
    "        node_op_unary.__init__(self, name, input1)\n",
    "        \n",
    "    def compute(self):\n",
    "        \"\"\"\n",
    "        compute output of this node: abs(input)\n",
    "        \"\"\"\n",
    "        self.value = abs(self.input1.value)\n",
    "        \n",
    "    def derive(self, w):\n",
    "        \"\"\"\n",
    "        compute the derivative of this node\n",
    "        with respect to node <w>\n",
    "        \"\"\"\n",
    "        if w.value > 0.0:\n",
    "            return 1.0\n",
    "        elif w.value < 0:\n",
    "            return -1.0\n",
    "        else:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building up a simple computation graph: a single neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neuron will have 3 inputs and 3 weights will be learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3 input nodes\n",
    "w1 = node(\"w1 (input)\")\n",
    "w2 = node(\"w2 (input)\")\n",
    "w3 = node(\"w3 (input)\")\n",
    "\n",
    "# 3 parameter nodes (weights)\n",
    "w4 = node(\"w4 (weight)\")\n",
    "w5 = node(\"w5 (weight)\")\n",
    "w6 = node(\"w6 (weight)\")\n",
    "\n",
    "# computation of activation\n",
    "w7 = node_op_mult(\"w7=w1*w4\", w1,w4)\n",
    "w8 = node_op_mult(\"w8=w2*w5\", w2,w5)\n",
    "w9 = node_op_mult(\"w9=w3*w6\", w3,w6)\n",
    "w10 = node_op_add(\"w10=w7+w8\", w7,w8)\n",
    "w11 = node_op_add(\"w11=w10+w9\", w10,w9)\n",
    "\n",
    "# computation of output value\n",
    "w12 = node_op_relu(\"w12=relu(w11)\", w11)\n",
    "\n",
    "# teacher value\n",
    "w13 = node(\"w13=teacher value\")\n",
    "\n",
    "# computation of loss\n",
    "w14 = node_op_sub(\"w14=w13-w12\", w13,w12)\n",
    "w15 = node_op_abs(\"w15=abs(w14)\", w14)\n",
    "\n",
    "# add all generated nodes to a Python list\n",
    "all_nodes = [w1,w2,w3,w4,w5,w6,w7,w8,w9,w10,w11,w12,w13,w14,w15]\n",
    "\n",
    "def feedforward(all_nodes):\n",
    "    \"\"\"\n",
    "    Let all nodes compute their outputs\n",
    "    starting from the first node\n",
    "    and going to the last node in the list\n",
    "    \"\"\"\n",
    "    \n",
    "    for n in all_nodes:\n",
    "        n.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1.value = 2.0\n",
    "w2.value = 1.0\n",
    "w3.value = 1.0\n",
    "w4.value = 10.0\n",
    "\n",
    "feedforward(all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w7.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w11.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w12.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w13.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-20.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w14.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w15.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backpropagation(all_nodes):\n",
    "    \"\"\"    \n",
    "    For each computation node w, compute:\n",
    "    \n",
    "           d loss    d loss         d next_node\n",
    "    _w =   ------ =  ----------- *  ----------- \n",
    "           d w       d next_node    d w\n",
    "                        \n",
    "         = next_node._w * dnext_dw\n",
    "         = (how does the next node change the output?) *\n",
    "           (how does this node change the output of the next node?)\n",
    "          \n",
    "    In other words: do reverse-mode autodiff\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    nr_nodes = len(all_nodes)\n",
    "    \n",
    "    # set seed variable\n",
    "    all_nodes[-1]._w = 1.0\n",
    "    \n",
    "    # go through all nodes, but in reverse order\n",
    "    for w in reversed( all_nodes[0:nr_nodes-1] ):\n",
    "        \n",
    "        # compute how this node\n",
    "        # changes the output of the error node\n",
    "        w._w = 0.0\n",
    "        \n",
    "        # multi-variate chain rule\n",
    "        for next_node in w.is_input_for:\n",
    "            # compute the derivative of the next node\n",
    "            # with respect to node n\n",
    "            dnext_dw = next_node.derive( w )\n",
    "            #print(\"\\tcomputing dnext_dw = d {} / d {} = {}\"\n",
    "            #      .format(next_node.name, w.name, dnext_dw) )\n",
    "            #print(\"\\tnext_node._w = \", next_node._w)\n",
    "            w._w += next_node._w * dnext_dw\n",
    "            \n",
    "        #print(\"computed _{} = {}\".format(w.name, w._w) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "backpropagation(all_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us train a single neuron to learn to add the 3 inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with random start weights and check whether the training procedure correctly sets the weights, such that the outputs are as desired:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 10\n",
      "\t(w4,w5,w6) = (0.2422,1.3296,0.8517)\n",
      "step: 20\n",
      "\t(w4,w5,w6) = (0.3002,1.3530,0.8874)\n",
      "step: 30\n",
      "\t(w4,w5,w6) = (0.3551,1.3792,0.9273)\n",
      "step: 40\n",
      "\t(w4,w5,w6) = (0.3906,1.3857,0.9295)\n",
      "step: 50\n",
      "\t(w4,w5,w6) = (0.4273,1.3950,0.9626)\n",
      "step: 60\n",
      "\t(w4,w5,w6) = (0.4648,1.4021,0.9710)\n",
      "step: 70\n",
      "\t(w4,w5,w6) = (0.4930,1.4018,0.9746)\n",
      "step: 80\n",
      "\t(w4,w5,w6) = (0.5206,1.3893,0.9893)\n",
      "step: 90\n",
      "\t(w4,w5,w6) = (0.5424,1.3843,0.9931)\n",
      "step: 100\n",
      "\t(w4,w5,w6) = (0.5648,1.3753,0.9967)\n",
      "step: 110\n",
      "\t(w4,w5,w6) = (0.5823,1.3465,0.9871)\n",
      "step: 120\n",
      "\t(w4,w5,w6) = (0.6070,1.3421,0.9759)\n",
      "step: 130\n",
      "\t(w4,w5,w6) = (0.6369,1.3426,0.9948)\n",
      "step: 140\n",
      "\t(w4,w5,w6) = (0.6575,1.3301,0.9936)\n",
      "step: 150\n",
      "\t(w4,w5,w6) = (0.6738,1.3210,0.9908)\n",
      "step: 160\n",
      "\t(w4,w5,w6) = (0.6838,1.2936,0.9978)\n",
      "step: 170\n",
      "\t(w4,w5,w6) = (0.7218,1.2819,1.0214)\n",
      "step: 180\n",
      "\t(w4,w5,w6) = (0.7336,1.2622,1.0198)\n",
      "step: 190\n",
      "\t(w4,w5,w6) = (0.7315,1.2314,1.0055)\n",
      "step: 200\n",
      "\t(w4,w5,w6) = (0.7454,1.2122,0.9982)\n",
      "step: 210\n",
      "\t(w4,w5,w6) = (0.7529,1.1943,0.9878)\n",
      "step: 220\n",
      "\t(w4,w5,w6) = (0.7803,1.2005,1.0049)\n",
      "step: 230\n",
      "\t(w4,w5,w6) = (0.7997,1.1884,1.0029)\n",
      "step: 240\n",
      "\t(w4,w5,w6) = (0.8177,1.1855,1.0025)\n",
      "step: 250\n",
      "\t(w4,w5,w6) = (0.8402,1.1822,0.9940)\n",
      "step: 260\n",
      "\t(w4,w5,w6) = (0.8661,1.1693,0.9958)\n",
      "step: 270\n",
      "\t(w4,w5,w6) = (0.8687,1.1364,1.0058)\n",
      "step: 280\n",
      "\t(w4,w5,w6) = (0.8737,1.1261,1.0072)\n",
      "step: 290\n",
      "\t(w4,w5,w6) = (0.9008,1.1270,1.0136)\n",
      "step: 300\n",
      "\t(w4,w5,w6) = (0.8852,1.0884,1.0073)\n",
      "step: 310\n",
      "\t(w4,w5,w6) = (0.8831,1.0579,0.9782)\n",
      "step: 320\n",
      "\t(w4,w5,w6) = (0.9277,1.0700,1.0098)\n",
      "step: 330\n",
      "\t(w4,w5,w6) = (0.9572,1.0745,1.0264)\n",
      "step: 340\n",
      "\t(w4,w5,w6) = (0.9408,1.0388,1.0130)\n",
      "step: 350\n",
      "\t(w4,w5,w6) = (0.9533,1.0185,1.0099)\n",
      "step: 360\n",
      "\t(w4,w5,w6) = (0.9741,1.0255,1.0234)\n",
      "step: 370\n",
      "\t(w4,w5,w6) = (0.9892,1.0170,1.0109)\n",
      "step: 380\n",
      "\t(w4,w5,w6) = (0.9836,1.0087,1.0062)\n",
      "step: 390\n",
      "\t(w4,w5,w6) = (0.9964,1.0064,0.9992)\n",
      "step: 400\n",
      "\t(w4,w5,w6) = (1.0009,1.0039,1.0007)\n",
      "step: 410\n",
      "\t(w4,w5,w6) = (0.9919,0.9930,0.9942)\n",
      "step: 420\n",
      "\t(w4,w5,w6) = (1.0060,1.0063,0.9975)\n",
      "step: 430\n",
      "\t(w4,w5,w6) = (0.9915,0.9971,1.0004)\n",
      "step: 440\n",
      "\t(w4,w5,w6) = (1.0025,0.9922,0.9934)\n",
      "step: 450\n",
      "\t(w4,w5,w6) = (1.0069,1.0006,0.9988)\n",
      "step: 460\n",
      "\t(w4,w5,w6) = (0.9994,0.9986,1.0020)\n",
      "step: 470\n",
      "\t(w4,w5,w6) = (1.0110,1.0014,1.0007)\n",
      "step: 480\n",
      "\t(w4,w5,w6) = (1.0095,0.9963,0.9941)\n",
      "step: 490\n",
      "\t(w4,w5,w6) = (1.0019,0.9936,0.9968)\n",
      "step: 500\n",
      "\t(w4,w5,w6) = (0.9999,0.9979,0.9938)\n",
      "step: 510\n",
      "\t(w4,w5,w6) = (1.0101,1.0059,0.9925)\n",
      "step: 520\n",
      "\t(w4,w5,w6) = (1.0078,0.9982,0.9995)\n",
      "step: 530\n",
      "\t(w4,w5,w6) = (1.0050,0.9980,1.0070)\n",
      "step: 540\n",
      "\t(w4,w5,w6) = (1.0025,0.9935,0.9949)\n",
      "step: 550\n",
      "\t(w4,w5,w6) = (1.0113,0.9925,1.0014)\n",
      "step: 560\n",
      "\t(w4,w5,w6) = (1.0073,0.9886,0.9923)\n",
      "step: 570\n",
      "\t(w4,w5,w6) = (1.0083,0.9927,1.0026)\n",
      "step: 580\n",
      "\t(w4,w5,w6) = (0.9974,0.9975,0.9968)\n",
      "step: 590\n",
      "\t(w4,w5,w6) = (1.0012,1.0084,1.0001)\n",
      "step: 600\n",
      "\t(w4,w5,w6) = (1.0021,0.9975,1.0033)\n",
      "step: 610\n",
      "\t(w4,w5,w6) = (0.9984,1.0081,0.9977)\n",
      "step: 620\n",
      "\t(w4,w5,w6) = (1.0125,1.0012,1.0059)\n",
      "step: 630\n",
      "\t(w4,w5,w6) = (1.0115,1.0009,1.0048)\n",
      "step: 640\n",
      "\t(w4,w5,w6) = (1.0032,1.0058,1.0000)\n",
      "step: 650\n",
      "\t(w4,w5,w6) = (1.0000,0.9933,0.9987)\n",
      "step: 660\n",
      "\t(w4,w5,w6) = (1.0013,0.9991,1.0126)\n",
      "step: 670\n",
      "\t(w4,w5,w6) = (0.9981,1.0019,1.0062)\n",
      "step: 680\n",
      "\t(w4,w5,w6) = (1.0004,0.9982,1.0079)\n",
      "step: 690\n",
      "\t(w4,w5,w6) = (1.0035,0.9910,1.0065)\n",
      "step: 700\n",
      "\t(w4,w5,w6) = (1.0030,0.9918,1.0144)\n",
      "step: 710\n",
      "\t(w4,w5,w6) = (0.9946,0.9940,1.0101)\n",
      "step: 720\n",
      "\t(w4,w5,w6) = (1.0038,1.0013,0.9976)\n",
      "step: 730\n",
      "\t(w4,w5,w6) = (1.0133,1.0008,0.9982)\n",
      "step: 740\n",
      "\t(w4,w5,w6) = (0.9946,1.0041,0.9973)\n",
      "step: 750\n",
      "\t(w4,w5,w6) = (1.0016,1.0068,1.0015)\n",
      "step: 760\n",
      "\t(w4,w5,w6) = (1.0046,1.0029,0.9998)\n",
      "step: 770\n",
      "\t(w4,w5,w6) = (0.9982,0.9993,0.9997)\n",
      "step: 780\n",
      "\t(w4,w5,w6) = (1.0053,1.0042,0.9963)\n",
      "step: 790\n",
      "\t(w4,w5,w6) = (1.0026,0.9978,1.0044)\n",
      "step: 800\n",
      "\t(w4,w5,w6) = (0.9985,1.0005,0.9992)\n",
      "step: 810\n",
      "\t(w4,w5,w6) = (0.9858,1.0070,1.0058)\n",
      "step: 820\n",
      "\t(w4,w5,w6) = (0.9923,0.9927,0.9954)\n",
      "step: 830\n",
      "\t(w4,w5,w6) = (1.0011,1.0077,1.0009)\n",
      "step: 840\n",
      "\t(w4,w5,w6) = (0.9952,0.9989,0.9905)\n",
      "step: 850\n",
      "\t(w4,w5,w6) = (0.9937,1.0075,0.9894)\n",
      "step: 860\n",
      "\t(w4,w5,w6) = (0.9965,0.9943,1.0040)\n",
      "step: 870\n",
      "\t(w4,w5,w6) = (1.0015,0.9989,0.9988)\n",
      "step: 880\n",
      "\t(w4,w5,w6) = (0.9962,0.9948,1.0127)\n",
      "step: 890\n",
      "\t(w4,w5,w6) = (1.0005,1.0062,1.0124)\n",
      "step: 900\n",
      "\t(w4,w5,w6) = (0.9951,0.9951,0.9978)\n",
      "step: 910\n",
      "\t(w4,w5,w6) = (0.9980,0.9948,0.9946)\n",
      "step: 920\n",
      "\t(w4,w5,w6) = (1.0072,1.0003,0.9942)\n",
      "step: 930\n",
      "\t(w4,w5,w6) = (0.9999,1.0140,0.9958)\n",
      "step: 940\n",
      "\t(w4,w5,w6) = (0.9957,0.9937,0.9940)\n",
      "step: 950\n",
      "\t(w4,w5,w6) = (1.0053,1.0080,1.0035)\n",
      "step: 960\n",
      "\t(w4,w5,w6) = (1.0002,1.0118,0.9994)\n",
      "step: 970\n",
      "\t(w4,w5,w6) = (1.0101,1.0093,1.0019)\n",
      "step: 980\n",
      "\t(w4,w5,w6) = (1.0042,1.0006,0.9837)\n",
      "step: 990\n",
      "\t(w4,w5,w6) = (1.0024,1.0172,0.9936)\n",
      "step: 1000\n",
      "\t(w4,w5,w6) = (0.9962,1.0034,0.9822)\n"
     ]
    }
   ],
   "source": [
    "from random import random\n",
    "\n",
    "# set start weights\n",
    "w4.value = 0.2\n",
    "w5.value = 1.3\n",
    "w6.value = 0.8\n",
    "\n",
    "show_debug_info = False\n",
    "learn_rate = 0.01\n",
    "steps = 1000\n",
    "errors = []\n",
    "for step in range(1,steps+1):\n",
    "    \n",
    "    if show_debug_info:\n",
    "        print(\"step:\", step)\n",
    "    else:\n",
    "        if step % 10 == 0:\n",
    "            print(\"step:\", step)\n",
    "            print(\"\\t(w4,w5,w6) = ({:.4f},{:.4f},{:.4f})\"\n",
    "                  .format(w4.value, w5.value, w6.value) )\n",
    "        \n",
    "    \n",
    "    # 1. randomly generate 3 input values\n",
    "    w1.value = random()\n",
    "    w2.value = random()\n",
    "    w3.value = random()\n",
    "    if show_debug_info:\n",
    "        print(\"\\tinput vec: ({0:.2},{1:.2},{2:.2})\"\n",
    "              .format(w1.value,w2.value,w3.value))\n",
    "    \n",
    "    # 2. compute and set teacher value\n",
    "    w13.value = w1.value + w2.value + w3.value\n",
    "    \n",
    "    # 3. forward propagation\n",
    "    feedforward(all_nodes)\n",
    "    \n",
    "    # 4. compare actual output with teacher value\n",
    "    if show_debug_info:\n",
    "        print(\"\\tis: {0:.2} vs. teacher: {1:.2}\"\n",
    "              .format(w12.value, w13.value))\n",
    "    \n",
    "    # 5. train (adapt) weights?\n",
    "    if True:\n",
    "            \n",
    "        # 5.1 compute gradient\n",
    "        backpropagation(all_nodes)\n",
    "        \n",
    "        # 5.2 show gradient\n",
    "        if show_debug_info:\n",
    "            print(\"\\tThe gradient is: ({:.2f},{:.2f},{:.2f})\"\n",
    "                  .format(w4._w, w5._w, w6._w) )\n",
    "        \n",
    "        # 5.3 adapt weights\n",
    "        w4.value += learn_rate * -w4._w\n",
    "        w5.value += learn_rate * -w5._w\n",
    "        w6.value += learn_rate * -w6._w\n",
    "            \n",
    "    # 6. compute error and store it in a list\n",
    "    error = abs(w12.value - w13.value)\n",
    "    errors.append( error )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nu4hIDvr/XfD6A0j5Q2QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2de8c8ffda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
